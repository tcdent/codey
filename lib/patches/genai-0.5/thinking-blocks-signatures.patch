diff --git a/src/adapter/adapters/anthropic/adapter_impl.rs b/src/adapter/adapters/anthropic/adapter_impl.rs
index bb08ce6..f1825d9 100644
--- a/src/adapter/adapters/anthropic/adapter_impl.rs
+++ b/src/adapter/adapters/anthropic/adapter_impl.rs
@@ -488,6 +488,7 @@ impl AnthropicAdapter {
 									}));
 								}
 								ContentPart::ThoughtSignature(_) => {}
+								ContentPart::Thinking(_) => {}
 							}
 						}
 						let values = apply_cache_control_to_parts(is_cache_control, values);
@@ -495,14 +496,24 @@ impl AnthropicAdapter {
 					}
 				}
 
-				// Assistant can mix text and tool_use entries.
+				// Assistant can mix text, thinking, and tool_use entries.
 				ChatRole::Assistant => {
 					let mut values: Vec<Value> = Vec::new();
 					let mut has_tool_use = false;
 					let mut has_text = false;
+					let mut has_thinking = false;
 
 					for part in msg.content {
 						match part {
+							ContentPart::Thinking(thinking) => {
+								has_thinking = true;
+								// Thinking blocks must be passed back with signature for tool use
+								values.push(json!({
+									"type": "thinking",
+									"thinking": thinking.thinking,
+									"signature": thinking.signature,
+								}));
+							}
 							ContentPart::Text(text) => {
 								has_text = true;
 								values.push(json!({"type": "text", "text": text}));
@@ -524,7 +535,7 @@ impl AnthropicAdapter {
 						}
 					}
 
-					if !has_tool_use && has_text && !is_cache_control && values.len() == 1 {
+					if !has_tool_use && !has_thinking && has_text && !is_cache_control && values.len() == 1 {
 						// Optimize to simple string when it's only one text part and no cache control.
 						let text = values
 							.first()
diff --git a/src/adapter/adapters/anthropic/streamer.rs b/src/adapter/adapters/anthropic/streamer.rs
index 1c18c37..9f7f08c 100644
--- a/src/adapter/adapters/anthropic/streamer.rs
+++ b/src/adapter/adapters/anthropic/streamer.rs
@@ -1,6 +1,6 @@
 use crate::adapter::adapters::support::{StreamerCapturedData, StreamerOptions};
 use crate::adapter::inter_stream::{InterStreamEnd, InterStreamEvent};
-use crate::chat::{ChatOptionsSet, ToolCall, Usage};
+use crate::chat::{ChatOptionsSet, Thinking, ToolCall, Usage};
 use crate::webc::{Event, EventSourceStream};
 use crate::{Error, ModelIden, Result};
 use serde_json::{Map, Value};
@@ -23,7 +23,7 @@ pub struct AnthropicStreamer {
 enum InProgressBlock {
 	Text,
 	ToolUse { id: String, name: String, input: String },
-	Thinking,
+	Thinking { content: String, signature: String },
 }
 
 impl AnthropicStreamer {
@@ -71,7 +71,12 @@ impl futures::Stream for AnthropicStreamer {
 
 							match data.x_get_str("/content_block/type") {
 								Ok("text") => self.in_progress_block = InProgressBlock::Text,
-								Ok("thinking") => self.in_progress_block = InProgressBlock::Thinking,
+								Ok("thinking") => {
+									self.in_progress_block = InProgressBlock::Thinking {
+										content: String::new(),
+										signature: String::new(),
+									}
+								}
 								Ok("tool_use") => {
 									self.in_progress_block = InProgressBlock::ToolUse {
 										id: data.x_take("/content_block/id")?,
@@ -114,10 +119,15 @@ impl futures::Stream for AnthropicStreamer {
 									input.push_str(data.x_get_str("/delta/partial_json")?);
 									continue;
 								}
-								InProgressBlock::Thinking => {
-									let thinking: String = data.x_take("/delta/thinking")?;
+								InProgressBlock::Thinking {
+								content: thinking_content,
+								signature: thinking_signature,
+							} => {
+								// Handle thinking_delta
+								if let Ok(thinking) = data.x_take::<String>("/delta/thinking") {
+									thinking_content.push_str(&thinking);
 
-									// Add to the captured_thinking if chat options say so
+									// Add to the captured_reasoning if chat options say so
 									if self.options.capture_reasoning_content {
 										match self.captured_data.reasoning_content {
 											Some(ref mut r) => r.push_str(&thinking),
@@ -127,6 +137,15 @@ impl futures::Stream for AnthropicStreamer {
 
 									return Poll::Ready(Some(Ok(InterStreamEvent::ReasoningChunk(thinking))));
 								}
+
+								// Handle signature_delta
+								if let Ok(sig) = data.x_take::<String>("/delta/signature") {
+									thinking_signature.push_str(&sig);
+									continue;
+								}
+
+								continue;
+							}
 							}
 						}
 						"content_block_stop" => {
@@ -155,8 +174,21 @@ impl futures::Stream for AnthropicStreamer {
 
 									return Poll::Ready(Some(Ok(InterStreamEvent::ToolCallChunk(tc))));
 								}
-								_ => {
-									// no-op for remaining block types
+								InProgressBlock::Thinking { content, signature } => {
+									// Capture complete thinking block with signature
+									if !content.is_empty() || !signature.is_empty() {
+										let thinking_block = Thinking {
+											thinking: content,
+											signature,
+										};
+										match self.captured_data.thinking_blocks {
+											Some(ref mut blocks) => blocks.push(thinking_block),
+											None => self.captured_data.thinking_blocks = Some(vec![thinking_block]),
+										}
+									}
+								}
+								InProgressBlock::Text => {
+									// no-op for text blocks
 								}
 							}
 
@@ -190,9 +222,9 @@ impl futures::Stream for AnthropicStreamer {
 								captured_reasoning_content: self.captured_data.reasoning_content.take(),
 								captured_tool_calls: self.captured_data.tool_calls.take(),
 								captured_thought_signatures: None,
+								captured_thinking_blocks: self.captured_data.thinking_blocks.take(),
 							};
 
-							// TODO: Need to capture the data as needed
 							return Poll::Ready(Some(Ok(InterStreamEvent::End(inter_stream_end))));
 						}
 
diff --git a/src/adapter/adapters/cohere/streamer.rs b/src/adapter/adapters/cohere/streamer.rs
index f17d1e0..84f5554 100644
--- a/src/adapter/adapters/cohere/streamer.rs
+++ b/src/adapter/adapters/cohere/streamer.rs
@@ -109,6 +109,7 @@ impl futures::Stream for CohereStreamer {
 										captured_reasoning_content: self.captured_data.reasoning_content.take(),
 										captured_tool_calls: self.captured_data.tool_calls.take(),
 										captured_thought_signatures: None,
+										captured_thinking_blocks: None,
 									};
 
 									InterStreamEvent::End(inter_stream_end)
diff --git a/src/adapter/adapters/gemini/adapter_impl.rs b/src/adapter/adapters/gemini/adapter_impl.rs
index 41f30c0..3e26c02 100644
--- a/src/adapter/adapters/gemini/adapter_impl.rs
+++ b/src/adapter/adapters/gemini/adapter_impl.rs
@@ -558,6 +558,7 @@ impl GeminiAdapter {
 									"thoughtSignature": thought
 								}));
 							}
+							ContentPart::Thinking(_) => {}
 						}
 					}
 
@@ -625,6 +626,11 @@ impl GeminiAdapter {
 									parts_values.push(json!({"thoughtSignature": thought}));
 								}
 							}
+							ContentPart::Thinking(_) => {
+								if let Some(thought) = pending_thought.take() {
+									parts_values.push(json!({"thoughtSignature": thought}));
+								}
+							}
 						}
 					}
 					if let Some(thought) = pending_thought {
diff --git a/src/adapter/adapters/gemini/streamer.rs b/src/adapter/adapters/gemini/streamer.rs
index ab9c2ef..d5c94b1 100644
--- a/src/adapter/adapters/gemini/streamer.rs
+++ b/src/adapter/adapters/gemini/streamer.rs
@@ -65,6 +65,7 @@ impl futures::Stream for GeminiStreamer {
 								captured_reasoning_content: self.captured_data.reasoning_content.take(),
 								captured_tool_calls: self.captured_data.tool_calls.take(),
 								captured_thought_signatures: self.captured_data.thought_signatures.take(),
+								captured_thinking_blocks: None,
 							};
 
 							return Poll::Ready(Some(Ok(InterStreamEvent::End(inter_stream_end))));
diff --git a/src/adapter/adapters/openai/adapter_impl.rs b/src/adapter/adapters/openai/adapter_impl.rs
index 93d1a8e..ec1712c 100644
--- a/src/adapter/adapters/openai/adapter_impl.rs
+++ b/src/adapter/adapters/openai/adapter_impl.rs
@@ -453,6 +453,7 @@ impl OpenAIAdapter {
 								ContentPart::ToolCall(_) => (),
 								ContentPart::ToolResponse(_) => (),
 								ContentPart::ThoughtSignature(_) => (),
+								ContentPart::Thinking(_) => (),
 							}
 						}
 						messages.push(json! ({"role": "user", "content": values}));
@@ -482,7 +483,8 @@ impl OpenAIAdapter {
 							// TODO: Probably need towarn on this one (probably need to add binary here)
 							ContentPart::Binary(_) => (),
 							ContentPart::ToolResponse(_) => (),
-							ContentPart::ThoughtSignature(_) => {}
+							ContentPart::ThoughtSignature(_) => {},
+							ContentPart::Thinking(_) => {},
 						}
 					}
 					let content = texts.join("\n\n");
diff --git a/src/adapter/adapters/openai/streamer.rs b/src/adapter/adapters/openai/streamer.rs
index e16e562..284f954 100644
--- a/src/adapter/adapters/openai/streamer.rs
+++ b/src/adapter/adapters/openai/streamer.rs
@@ -137,6 +137,7 @@ impl futures::Stream for OpenAIStreamer {
 							captured_reasoning_content: self.captured_data.reasoning_content.take(),
 							captured_tool_calls,
 							captured_thought_signatures: None,
+							captured_thinking_blocks: None,
 						};
 
 						return Poll::Ready(Some(Ok(InterStreamEvent::End(inter_stream_end))));
diff --git a/src/adapter/adapters/openai_resp/adapter_impl.rs b/src/adapter/adapters/openai_resp/adapter_impl.rs
index 4ea2ae0..f18c255 100644
--- a/src/adapter/adapters/openai_resp/adapter_impl.rs
+++ b/src/adapter/adapters/openai_resp/adapter_impl.rs
@@ -392,6 +392,7 @@ impl OpenAIRespAdapter {
 								ContentPart::ToolCall(_) => (),
 								ContentPart::ToolResponse(_) => (),
 								ContentPart::ThoughtSignature(_) => (),
+								ContentPart::Thinking(_) => (),
 							}
 						}
 						input_items.push(json! ({"role": "user", "content": values}));
@@ -435,6 +436,7 @@ impl OpenAIRespAdapter {
 							ContentPart::Binary(_) => {}
 							ContentPart::ToolResponse(_) => {}
 							ContentPart::ThoughtSignature(_) => {}
+							ContentPart::Thinking(_) => {}
 						}
 					}
 
diff --git a/src/adapter/adapters/support.rs b/src/adapter/adapters/support.rs
index d78f31d..dbb3284 100644
--- a/src/adapter/adapters/support.rs
+++ b/src/adapter/adapters/support.rs
@@ -2,7 +2,7 @@
 //! It should be private to the `crate::adapter::adapters` module.
 
 use crate::ModelIden;
-use crate::chat::{ChatOptionsSet, Usage};
+use crate::chat::{ChatOptionsSet, Thinking, Usage};
 use crate::resolver::AuthData;
 use crate::{Error, Result};
 
@@ -47,6 +47,8 @@ pub struct StreamerCapturedData {
 	pub reasoning_content: Option<String>,
 	pub tool_calls: Option<Vec<crate::chat::ToolCall>>,
 	pub thought_signatures: Option<Vec<String>>,
+	/// Captured thinking blocks with content and signatures (Anthropic)
+	pub thinking_blocks: Option<Vec<Thinking>>,
 }
 
 // endregion: --- Streamer Captured Data
diff --git a/src/adapter/inter_stream.rs b/src/adapter/inter_stream.rs
index ca1c045..71d6348 100644
--- a/src/adapter/inter_stream.rs
+++ b/src/adapter/inter_stream.rs
@@ -5,7 +5,7 @@
 //!
 //! NOTE: This might be removed at some point as it may not be needed, and we could go directly to the GenAI stream.
 
-use crate::chat::Usage;
+use crate::chat::{Thinking, Usage};
 
 #[derive(Debug, Default)]
 pub struct InterStreamEnd {
@@ -22,7 +22,12 @@ pub struct InterStreamEnd {
 	pub captured_tool_calls: Option<Vec<crate::chat::ToolCall>>,
 
 	// When `ChatOptions..capture_thought_signatures == true` (implied or explicit)
+	// Used for Gemini thought signatures (opaque strings)
 	pub captured_thought_signatures: Option<Vec<String>>,
+
+	// Captured thinking blocks with content and signatures (Anthropic)
+	// Captured when thinking is enabled and tool calls are present
+	pub captured_thinking_blocks: Option<Vec<Thinking>>,
 }
 
 /// Intermediary StreamEvent
diff --git a/src/chat/chat_stream.rs b/src/chat/chat_stream.rs
index 9b9aecd..7b41bcf 100644
--- a/src/chat/chat_stream.rs
+++ b/src/chat/chat_stream.rs
@@ -1,5 +1,5 @@
 use crate::adapter::inter_stream::{InterStreamEnd, InterStreamEvent};
-use crate::chat::{ChatMessage, ContentPart, MessageContent, ToolCall, Usage};
+use crate::chat::{ChatMessage, ContentPart, MessageContent, Thinking, ToolCall, Usage};
 use futures::Stream;
 use serde::{Deserialize, Serialize};
 use std::pin::Pin;
@@ -115,6 +115,10 @@ pub struct StreamEnd {
 
 	/// Captured reasoning content if `ChatOptions.capture_reasoning` is enabled.
 	pub captured_reasoning_content: Option<String>,
+
+	/// Captured thinking blocks with content and signatures (Anthropic).
+	/// These are automatically captured when extended thinking is enabled.
+	pub captured_thinking_blocks: Option<Vec<Thinking>>,
 }
 
 impl From<InterStreamEnd> for StreamEnd {
@@ -171,6 +175,7 @@ impl From<InterStreamEnd> for StreamEnd {
 			captured_usage: inter_end.captured_usage,
 			captured_content,
 			captured_reasoning_content: inter_end.captured_reasoning_content,
+			captured_thinking_blocks: inter_end.captured_thinking_blocks,
 		}
 	}
 }
@@ -261,6 +266,16 @@ impl StreamEnd {
 			thought_signatures,
 		))
 	}
+
+	/// Returns captured thinking blocks, if any.
+	pub fn captured_thinking_blocks(&self) -> Option<&Vec<Thinking>> {
+		self.captured_thinking_blocks.as_ref()
+	}
+
+	/// Consumes `self` and returns all captured thinking blocks, if any.
+	pub fn captured_into_thinking_blocks(self) -> Option<Vec<Thinking>> {
+		self.captured_thinking_blocks
+	}
 }
 
 // endregion: --- ChatStreamEvent
diff --git a/src/chat/content_part.rs b/src/chat/content_part.rs
index 6a44441..73f5235 100644
--- a/src/chat/content_part.rs
+++ b/src/chat/content_part.rs
@@ -5,6 +5,18 @@ use serde::{Deserialize, Serialize};
 use std::path::Path;
 use std::sync::Arc;
 
+/// A thinking block with content and cryptographic signature.
+///
+/// Used by Anthropic's extended thinking feature. The signature is required
+/// when passing thinking blocks back to the API for tool use continuation.
+#[derive(Debug, Clone, Serialize, Deserialize, Default)]
+pub struct Thinking {
+	/// The thinking/reasoning content.
+	pub thinking: String,
+	/// The cryptographic signature for this thinking block.
+	pub signature: String,
+}
+
 /// A single content segment in a chat message.
 ///
 /// Variants cover plain text, binary payloads (e.g., images/PDF), and tool calls/responses.
@@ -22,8 +34,13 @@ pub enum ContentPart {
 	#[from]
 	ToolResponse(ToolResponse),
 
+	/// Gemini thought signature (opaque string).
 	#[from(ignore)]
 	ThoughtSignature(String),
+
+	/// Anthropic thinking block with content and signature.
+	#[from]
+	Thinking(Thinking),
 }
 
 /// Constructors
@@ -161,6 +178,24 @@ impl ContentPart {
 			None
 		}
 	}
+
+	/// Borrow the thinking block if present.
+	pub fn as_thinking(&self) -> Option<&Thinking> {
+		if let ContentPart::Thinking(thinking) = self {
+			Some(thinking)
+		} else {
+			None
+		}
+	}
+
+	/// Extract the thinking block, consuming the part.
+	pub fn into_thinking(self) -> Option<Thinking> {
+		if let ContentPart::Thinking(thinking) = self {
+			Some(thinking)
+		} else {
+			None
+		}
+	}
 }
 
 /// Computed accessors
@@ -178,6 +213,7 @@ impl ContentPart {
 			ContentPart::ToolCall(tool_call) => tool_call.size(),
 			ContentPart::ToolResponse(tool_response) => tool_response.size(),
 			ContentPart::ThoughtSignature(thought) => thought.len(),
+			ContentPart::Thinking(thinking) => thinking.thinking.len() + thinking.signature.len(),
 		}
 	}
 }
@@ -224,8 +260,13 @@ impl ContentPart {
 		matches!(self, ContentPart::ToolResponse(_))
 	}
 
-	/// Returns true if this part is a thought.
+	/// Returns true if this part is a thought signature (Gemini).
 	pub fn is_thought_signature(&self) -> bool {
 		matches!(self, ContentPart::ThoughtSignature(_))
 	}
+
+	/// Returns true if this part is a thinking block (Anthropic).
+	pub fn is_thinking(&self) -> bool {
+		matches!(self, ContentPart::Thinking(_))
+	}
 }
diff --git a/tests/tests_p_anthropic.rs b/tests/tests_p_anthropic.rs
index 26ee141..7e57098 100644
--- a/tests/tests_p_anthropic.rs
+++ b/tests/tests_p_anthropic.rs
@@ -1,9 +1,11 @@
 mod support;
 
-use crate::support::{Check, TestResult, common_tests};
+use crate::support::{Check, TestResult, common_tests, seed_chat_req_tool_simple};
+use futures::StreamExt;
 use genai::adapter::AdapterKind;
-use genai::chat::ReasoningEffort;
+use genai::chat::{ChatMessage, ChatOptions, ChatStreamEvent, ContentPart, ReasoningEffort, ToolResponse};
 use genai::resolver::AuthData;
+use genai::{Client, Headers};
 use serial_test::serial;
 
 // "claude-3-haiku-20240307" cheapest
@@ -11,7 +13,6 @@ use serial_test::serial;
 // "claude-sonnet-4-20250514" (fail on test_chat_json_mode_ok)
 //
 const MODEL: &str = "claude-3-5-haiku-latest";
-// const MODEL_THINKING: &str = "claude-sonnet-4-5-20250929";
 const MODEL_THINKING: &str = "claude-opus-4-5";
 const MODEL_NS: &str = "anthropic::claude-3-5-haiku-latest";
 
@@ -148,6 +149,111 @@ async fn test_tool_full_flow_ok() -> TestResult<()> {
 	common_tests::common_test_tool_full_flow_ok(MODEL).await
 }
 
+/// Test that thinking blocks with signatures are properly captured during streaming
+/// and can be passed back to the API for tool use continuation.
+/// Uses interleaved-thinking beta header for extended thinking with tool use.
+#[tokio::test]
+#[serial(anthropic)]
+async fn test_tool_with_thinking_stream_ok() -> TestResult<()> {
+	// Use sonnet-4 which supports thinking without output_config issues
+	const MODEL_FOR_THINKING: &str = "claude-sonnet-4-20250514";
+
+	// -- Setup & Fixtures
+	let client = Client::default();
+	let chat_req = seed_chat_req_tool_simple();
+
+	// Enable interleaved thinking beta for tool use inside thinking blocks
+	let extra_headers = Headers::from(vec![(
+		"anthropic-beta".to_string(),
+		"interleaved-thinking-2025-05-14".to_string(),
+	)]);
+
+	let chat_options = ChatOptions::default()
+		.with_reasoning_effort(ReasoningEffort::Low)
+		.with_capture_tool_calls(true)
+		.with_extra_headers(extra_headers);
+
+	// -- Exec first request to get the tool calls with thinking
+	let chat_res = client
+		.exec_chat_stream(MODEL_FOR_THINKING, chat_req.clone(), Some(&chat_options))
+		.await?;
+
+	// Consume the stream and capture thinking blocks
+	let mut stream = chat_res.stream;
+	let mut reasoning_chunks: Vec<String> = Vec::new();
+
+	while let Some(event) = stream.next().await {
+		match event? {
+			ChatStreamEvent::ReasoningChunk(chunk) => {
+				reasoning_chunks.push(chunk.content);
+			}
+			ChatStreamEvent::End(mut end) => {
+				// Verify thinking blocks are captured
+				if let Some(ref thinking_blocks) = end.captured_thinking_blocks {
+					assert!(!thinking_blocks.is_empty(), "Should have captured thinking blocks");
+
+					// Verify each thinking block has both content and signature
+					for block in thinking_blocks {
+						assert!(!block.thinking.is_empty(), "Thinking content should not be empty");
+						assert!(!block.signature.is_empty(), "Signature should not be empty");
+					}
+
+					// Verify we have tool calls
+					let tool_calls = end.captured_tool_calls().ok_or("Should have tool calls")?;
+					assert!(!tool_calls.is_empty(), "Should have at least one tool call");
+
+					// Get tool call ID for response (before we move tool_calls)
+					let first_tool_call = tool_calls.first().ok_or("Should have at least one tool call")?;
+					let tool_call_id = first_tool_call.call_id.clone();
+
+					// Take ownership of captured data
+					let thinking_blocks = end.captured_thinking_blocks.take().unwrap();
+					let tool_calls = end.captured_into_tool_calls().unwrap();
+
+					// Build assistant message with thinking blocks and tool calls
+					let mut msg_content = genai::chat::MessageContent::default();
+					for thinking in thinking_blocks {
+						msg_content = msg_content.append(ContentPart::Thinking(thinking));
+					}
+					for tc in tool_calls {
+						msg_content = msg_content.append(ContentPart::ToolCall(tc));
+					}
+
+					// Simulate tool response
+					let tool_response =
+						ToolResponse::new(&tool_call_id, r#"{"weather": "Sunny", "temperature": "32C"}"#);
+
+					// Build the follow-up request
+					let chat_req = chat_req
+						.clone()
+						.append_message(ChatMessage {
+							role: genai::chat::ChatRole::Assistant,
+							content: msg_content,
+							options: None,
+						})
+						.append_message(tool_response);
+
+					// Execute the follow-up request (this verifies the thinking blocks can be sent back)
+					let final_res = client.exec_chat(MODEL_FOR_THINKING, chat_req, Some(&chat_options)).await?;
+
+					// Verify we got a response
+					let content = final_res.first_text().ok_or("Should have response text")?;
+					assert!(!content.is_empty(), "Response should not be empty");
+
+					return Ok(());
+				} else {
+					// Model might not have used thinking for this simple request
+					// That's OK - we still verify the streaming worked
+					return Ok(());
+				}
+			}
+			_ => {}
+		}
+	}
+
+	Err("Stream ended without End event".into())
+}
+
 // endregion: --- Tool Tests
 
 // region:    --- Resolver Tests
